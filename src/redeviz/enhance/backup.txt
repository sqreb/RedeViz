import torch as tr
from torch import nn
import torch.optim as optim
import numpy as np
import pickle
from redeviz.enhance.index import compute_neighbor_bin_loc
from redeviz.enhance.utils import select_device
import logging
import tempfile
import os

from redeviz.enhance.image_index import simulate_img_ST_data_from_bin_scRNA_worker, select_gene_bin_cnt_gene

class ImgStEmbSimiModel(nn.Module):
    def __init__(self, gene_num, bin_num):
        super().__init__()
        self.linear_relu_stack = nn.Sequential(
            nn.Linear(gene_num, 256),
            nn.BatchNorm1d(256),
            nn.ReLU(),
            nn.Linear(256, 512),
            nn.BatchNorm1d(512),
            nn.ReLU(),
            nn.Linear(512, bin_num),
            nn.Sigmoid()
        )
    
    def forward(self, x):
        simi = self.linear_relu_stack(x)
        return simi



def compute_simu_info_worker_by_simi_model(mu_simu, mu_rand_arr, simu_bin_index, simi_model, quantile_arr, ref_norm_gene_bin_pct, main_bin_type_ratio, neighbor_bin_expand_arr, N):
    bin_num = ref_norm_gene_bin_pct.shape[0]
    simu_cnt_arr = simulate_img_ST_data_from_bin_scRNA_worker(mu_simu, mu_rand_arr, main_bin_type_ratio, N)
    with tr.no_grad():
        img_simi = simi_model(simu_cnt_arr)
    img_simi = tr.permute(img_simi, [1, 0])
    quantile_simi = tr.quantile(img_simi[simu_bin_index, :], quantile_arr, 0)
    max_simi, arg_max_simi = tr.max(img_simi, 0)
    arg_max_simi_ratio = tr.bincount(arg_max_simi, minlength=bin_num) / N
    neightbor_max_simi_ratio = tr.matmul(neighbor_bin_expand_arr.reshape([-1, bin_num]).type(tr.float32), arg_max_simi_ratio.reshape([-1, 1])).reshape([-1, bin_num])
    return quantile_simi, neightbor_max_simi_ratio

def compute_simu_info_by_simi_model(gene_bin_pct, ref_norm_gene_bin_pct, neighbor_bin_expand_arr, simi_model, main_bin_type_ratio, UMI_per_bin, simulate_number_per_batch=1024, simulate_batch_num=20):
    device=gene_bin_pct.device

    bin_num, gene_num = gene_bin_pct.shape
    ave_gene_pct = gene_bin_pct.mean(0)
    mu_rand_arr = ave_gene_pct * UMI_per_bin / ave_gene_pct.sum()
    quantile_arr = tr.tensor([0, 0.05, 0.25, 0.5, 0.75, 0.95, 1], device=device)
    quantile_simi_li = list()
    neightbor_max_simi_ratio_li = list()
    for bin_index in range(bin_num):
        if bin_index % 10 == 0:
            logging.info(f"{bin_index} / {bin_num}")
        tmp_pct_arr = gene_bin_pct[bin_index,]
        tmp_mu_simu_arr = tmp_pct_arr * UMI_per_bin / ave_gene_pct.sum()
        quantile_simi = tr.zeros_like(quantile_arr, dtype=tr.float32, device=device)
        neightbor_max_simi_ratio = tr.zeros([neighbor_bin_expand_arr.shape[0], bin_num], dtype=tr.float64, device=device)
        for batch_index in range(simulate_batch_num):
            tmp_quantile_simi, tmp_neightbor_max_simi_ratio = compute_simu_info_worker_by_simi_model(tmp_mu_simu_arr, mu_rand_arr, bin_index, simi_model, quantile_arr,  ref_norm_gene_bin_pct, main_bin_type_ratio, neighbor_bin_expand_arr, simulate_number_per_batch)
            quantile_simi += tmp_quantile_simi
            neightbor_max_simi_ratio += tmp_neightbor_max_simi_ratio
        quantile_simi = quantile_simi / simulate_batch_num
        neightbor_max_simi_ratio = neightbor_max_simi_ratio / simulate_batch_num
        quantile_simi_li.append(quantile_simi)
        neightbor_max_simi_ratio_li.append(neightbor_max_simi_ratio)
        

    rand_quantile_simi = tr.zeros_like(quantile_arr, dtype=tr.float32)
    rand_neightbor_max_simi_ratio = tr.zeros([neighbor_bin_expand_arr.shape[0], bin_num], dtype=tr.float64, device=device)
    for batch_index in range(simulate_batch_num):
        tmp_rand_quantile_simi, tmp_rand_neightbor_max_simi_ratio = compute_simu_info_worker_by_simi_model(mu_rand_arr, mu_rand_arr, bin_index, simi_model, quantile_arr, ref_norm_gene_bin_pct, 1, neighbor_bin_expand_arr, simulate_number_per_batch)
        rand_quantile_simi = rand_quantile_simi + tmp_rand_quantile_simi
        rand_neightbor_max_simi_ratio = rand_neightbor_max_simi_ratio + tmp_rand_neightbor_max_simi_ratio
    rand_quantile_simi = rand_quantile_simi / simulate_batch_num
    rand_neightbor_max_simi_ratio = rand_neightbor_max_simi_ratio / simulate_batch_num
    quantile_simi_li.append(rand_quantile_simi)
    neightbor_max_simi_ratio_li.append(rand_neightbor_max_simi_ratio)
    quantile_simi_arr = tr.stack(quantile_simi_li, 0)
    neightbor_max_simi_ratio_arr = tr.stack(neightbor_max_simi_ratio_li, 1)
    return quantile_simi_arr, neightbor_max_simi_ratio_arr


def build_simi_model(ref_norm_gene_bin_pct: tr.tensor, gene_bin_pct: tr.tensor, bin_pheno_dist: tr.tensor, UMI_per_spot: float, embedding_resolution: float, bin_size: int, max_epoch=2000, N_sampel_per_epoch=100, early_stop_step=10):
    device = ref_norm_gene_bin_pct.device
    bin_num, gene_num = ref_norm_gene_bin_pct.shape
    pct_per_bin = tr.sum(gene_bin_pct, -1)

    pheno_very_close_mask_arr = (bin_pheno_dist<2).type(tr.float32).to(device)
    pheno_close_mask_arr = (bin_pheno_dist<(6/embedding_resolution)).type(tr.float32).to(device)
    pheno_far_mask_arr = (bin_pheno_dist>(12/embedding_resolution)).type(tr.float32).to(device)

    max_epoch = 2000
    model = ImgStEmbSimiModel(gene_num, bin_num).to(device)
    model.train()
    optimizer = optim.Adam(model.parameters(), 0.001)
    best_score = -1 * tr.inf
    best_epoch = 0
    with tempfile.TemporaryDirectory() as tmpdirname:
        for epoch in range(max_epoch):
            score = tr.tensor(0, dtype=tr.float32, device=device)
            for _ in range(N_sampel_per_epoch):
                mu_ST_bin_cnt = (gene_bin_pct+(0.01/gene_num))*UMI_per_spot*bin_size*bin_size/tr.mean(pct_per_bin) * tr.exp2(tr.distributions.normal.Normal(tr.tensor(0, dtype=tr.float32, device=device), tr.tensor(1, dtype=tr.float32, device=device)).sample([bin_num])).unsqueeze(-1)
                ST_bin_cnt = tr.distributions.poisson.Poisson(mu_ST_bin_cnt).sample()
                pred_simi_arr = model(ST_bin_cnt)

                argmax_simi_bin_index = tr.argmax(pred_simi_arr, -1)
                argmax_simi_pheno_dist = bin_pheno_dist[tr.arange(bin_num), argmax_simi_bin_index]

                argmax_pheno_dist_score = (argmax_simi_pheno_dist.reshape([-1, 1]) <= tr.tensor([0, 6, 9, 12], dtype=tr.float32, device=device)).type(tr.float32).mean(0)

                center_score = tr.mean(tr.diag(pred_simi_arr))
                close_score = tr.sum(pred_simi_arr * pheno_close_mask_arr) / tr.sum(pheno_close_mask_arr)
                very_close_score = tr.sum(pred_simi_arr * pheno_very_close_mask_arr) / tr.sum(pheno_close_mask_arr)
                far_score = 1 - tr.sum(pred_simi_arr * pheno_far_mask_arr) / tr.sum(pheno_far_mask_arr)
                max_far_score = 1 - tr.max(pred_simi_arr * pheno_far_mask_arr)
                score = score + far_score + close_score + very_close_score + max_far_score + 0.2*center_score + argmax_pheno_dist_score.sum()
            if score > best_score:
                best_score = score
                tr.save(model.state_dict(), os.path.join(tmpdirname, "CheckPoint.pth") )
                best_epoch = epoch
            else:
                if (epoch-best_epoch) > early_stop_step:
                    break
            cost = -1 * score
            cost.backward()
            optimizer.step()
            optimizer.zero_grad()
            print(f"""Epoch: {epoch}, Cost: {cost.detach().to("cpu").numpy()}, PhenoDist: {argmax_pheno_dist_score.detach().to("cpu").numpy()}""")
        model.load_state_dict(tr.load(os.path.join(tmpdirname, "CheckPoint.pth")))
    return model

def build_embedding_image_index_main(args):
    f_in = args.input
    f_out = args.output
    bin_size_li = args.bin_size  # (12, 18, 21)
    UMI_per_spot = args.UMI_per_spot
    f_select_gene = args.select_gene
    device = args.device_name

    if device is None:
        device = select_device()
    main_bin_type_ratio_li = tr.tensor([0.75])

    with open(f_in, "rb") as f:
        embedding_dict = pickle.load(f)

    gene_name_arr = embedding_dict["gene_name"]
    gene_bin_cnt = embedding_dict["gene_bin_cnt"]
    embedding_resolution = embedding_dict["embedding_resolution"]
    neightbor_expand_size = np.arange(int(embedding_resolution*4))
    cell_info_df = embedding_dict["cell_info"]
    select_embedding_info = embedding_dict["embedding_info"]

    select_gene_li = list()
    with open(f_select_gene, "r") as f:
        for line in f.readlines():
            select_gene_li.append(line.rstrip("\n"))
    
    gene_bin_pct, ref_norm_gene_bin_pct, gene_name_arr = select_gene_bin_cnt_gene(gene_bin_cnt, gene_name_arr, select_gene_li, device)
    logging.info(f"{len(gene_name_arr)} genes were found in reference data")

    total_pct_per_bin = tr.sum(gene_bin_pct, -1)
    Q75_pct_per_bin = tr.quantile(total_pct_per_bin, 0.75)
    expr_bin_index = total_pct_per_bin>(Q75_pct_per_bin/3)
    gene_bin_pct = gene_bin_pct[expr_bin_index,]
    ref_norm_gene_bin_pct = ref_norm_gene_bin_pct[expr_bin_index,]
    select_embedding_info = select_embedding_info[expr_bin_index.detach().to("cpu").numpy()]
    select_embedding_info["RowIndex"] = np.arange(select_embedding_info.shape[0])

    bin_emb_arr = tr.tensor(select_embedding_info[["Embedding1BinIndex", "Embedding2BinIndex", "Embedding3BinIndex"]].to_numpy(), dtype=tr.float32)
    bin_pheno_dist = tr.sqrt(tr.sum((bin_emb_arr.reshape([-1, 1, 3]) - bin_emb_arr.reshape([1, -1, 3])) ** 2 , -1)).to(device)

    simi_model_li = list()
    for bin_size in bin_size_li:
        logging.info(f"BinSize: {bin_size}")
        model = build_simi_model(ref_norm_gene_bin_pct, gene_bin_pct, bin_pheno_dist, UMI_per_spot, embedding_resolution, bin_size)
        simi_model_li.append(model)


    logging.info(f"Simulating spatial transcriptomics data and compute prior probability ...")
    neighbor_bin_expand_li = [compute_neighbor_bin_loc(select_embedding_info, expand_size, bin_index_name="RowIndex") for expand_size in neightbor_expand_size]
    neighbor_bin_expand_arr = tr.stack(neighbor_bin_expand_li, 0)
    neighbor_bin_expand_arr = neighbor_bin_expand_arr.to(device)
    bin_quantile_simi_li = list()
    bin_neightbor_max_simi_ratio_li = list()
    for bin_size, simi_model in zip(bin_size_li, simi_model_li):
        logging.info(f"Bin size: {bin_size}")
        UMI_per_bin = int(bin_size * bin_size * UMI_per_spot)
        main_type_ratio_quantile_simi_li = list()
        main_type_ratio_neightbor_max_simi_ratio_li = list()
        for main_bin_type_ratio in main_bin_type_ratio_li:
            logging.info(f"Main bin type cell ratio: {main_bin_type_ratio}")
            quantile_simi_arr, neightbor_max_simi_ratio_arr = compute_simu_info_by_simi_model(gene_bin_pct, ref_norm_gene_bin_pct, neighbor_bin_expand_arr, simi_model, main_bin_type_ratio, UMI_per_bin)
            main_type_ratio_quantile_simi_li.append(quantile_simi_arr)
            main_type_ratio_neightbor_max_simi_ratio_li.append(neightbor_max_simi_ratio_arr)
        main_type_ratio_quantile_simi_arr = tr.stack(main_type_ratio_quantile_simi_li, 0)
        main_type_ratio_neightbor_max_simi_ratio_arr = tr.stack(main_type_ratio_neightbor_max_simi_ratio_li, 0)
        bin_quantile_simi_li.append(main_type_ratio_quantile_simi_arr)
        bin_neightbor_max_simi_ratio_li.append(main_type_ratio_neightbor_max_simi_ratio_arr)
    index_dict = {
        "index_type": "Image",
        "gene_name": gene_name_arr,
        "norm_embedding_bin_pct": ref_norm_gene_bin_pct.to("cpu"),
        "simi_model": [model.to("cpu").state_dict() for model in simi_model_li],
        "neightbor_expand_size": neightbor_expand_size,
        "main_bin_type_ratio": main_bin_type_ratio_li,
        "bin_size": bin_size_li,
        "quantile_simi": [x.to("cpu") for x in bin_quantile_simi_li], # [bin_size, main_bin_type_ratio, SimuLabel: bin_size+1 (random), quantile_num]
        "neightbor_max_simi_ratio": [x.to("cpu") for x in bin_neightbor_max_simi_ratio_li],  # [bin_size, main_bin_type_ratio, neighbor_bin_expand_size, SimuLabel: bin_size (random), MaxSimiLabel: bin_size]
        "cell_info": cell_info_df,
        "embedding": embedding_dict["embedding"],
        "embedding_resolution": embedding_resolution,
        "embedding_dim": embedding_dict["embedding_dim"],
        "embedding_info": select_embedding_info
    }
    with open(f_out, "wb") as f:
        pickle.dump(index_dict, f)



class RedeVizImgBinIndex(RedeVizBinIndex):
    def __init__(self, f_pkl: str, cell_radius: int, device: str) -> None:
        with open(f_pkl, "rb") as f:
            dataset_dict = pickle.load(f)
        self.device = device
        self.bin_size = dataset_dict["bin_size"]
        self.bin_num = len(self.bin_size)
        self.max_bin_size = max(self.bin_size)
        self.cell_radius = cell_radius
        self.gene_name = dataset_dict["gene_name"]
        self.gene_num = len(self.gene_name)
        self.cell_info = dataset_dict["cell_info"]
        self.embedding_info = dataset_dict["embedding_info"]
        self.embedding_info["RowIndex"] = np.arange(self.embedding_info.shape[0])
        self.cell_info = self.cell_info[~np.isnan(self.cell_info["BinIndex"].to_numpy())]
        self.cell_info = self.embedding_info[["BinIndex", "RowIndex"]].merge(self.cell_info, how="inner")
        self.neightbor_expand_size = dataset_dict["neightbor_expand_size"]
        self.main_bin_type_ratio = dataset_dict["main_bin_type_ratio"]
        self.embedding_resolution = dataset_dict["embedding_resolution"]
        self.norm_embedding_bin_pct = dataset_dict["norm_embedding_bin_pct"].to(device)
        self.quantile_cos_simi = tr.stack(dataset_dict["quantile_simi"], 0).to(device)
        self.quantile_cos_simi = tr.permute(self.quantile_cos_simi, [2, 0, 3, 1])  # EmbeddingBinIndex, BinSize, Pct, MixRatio
        self.quantile_cos_simi = tr.concat([self.quantile_cos_simi, tr.unsqueeze(self.quantile_cos_simi[-1, :, :, :], 0)], 0)
        self.neightbor_max_cos_simi_ratio = tr.stack(dataset_dict["neightbor_max_simi_ratio"], 0).to(device)
        self.neightbor_max_cos_simi_ratio = tr.concat([self.neightbor_max_cos_simi_ratio, tr.unsqueeze(self.neightbor_max_cos_simi_ratio[:, :, :, -1, :], -2)], -2)
        self.neightbor_max_cos_simi_ratio = tr.permute(self.neightbor_max_cos_simi_ratio, [0, 1, 3, 4, 2])  # BinSize, MixRatio, EmbeddingBinLabel, MaxCosSimiEmbeddingBin, ExpandSize
        neightbor_max_cos_simi_max_score = tr.unsqueeze(tr.max(self.neightbor_max_cos_simi_ratio, -2)[0], -2)
        self.neightbor_max_cos_simi_score = self.neightbor_max_cos_simi_ratio / neightbor_max_cos_simi_max_score
        self.cell_type = np.sort(np.unique(self.cell_info["CellType"].to_numpy()))
        self.cell_type_num = len(self.cell_type)
        self.embedding_bin_num = self.embedding_info.shape[0]
        self.simi_model_li = list()
        for state_dict in dataset_dict["simi_model"]:
            model = ImgStEmbSimiModel(self.gene_num, self.embedding_bin_num)
            model.load_state_dict(state_dict)
            model = model.to(self.device)
            self.simi_model_li.append(model)
        self.bin_cell_type_ratio = self.compute_bin_cell_type_ratio_arr(self.cell_type, self.cell_info, self.embedding_bin_num, self.cell_type_num).to(device)
        self.bin_dist = self.compute_bin_dist(self.embedding_info).to(device)

    def compute_cos_simi(self, spot_data):
        spot_data = spot_data.coalesce()
        simi_li = list()
        for bin_size, simi_model in zip(self.bin_size, self.simi_model_li):
            expand_size = int((bin_size - 1) / 2)
            spot_data = spot_data.type(tr.float32).to(self.norm_embedding_bin_pct.device)
            smooth_spot_arr = SparseSumPooling2DV2(spot_data, expand_size, expand_size)
            smooth_spot_arr = smooth_spot_arr.to_dense()
            flat_smooth_spot_arr = smooth_spot_arr.reshape([-1, self.gene_num])
            flat_simi_arr = simi_model(flat_smooth_spot_arr) # [N, bin]
            tmp_simi = flat_simi_arr.reshape([spot_data.shape[1], spot_data.shape[2], self.embedding_bin_num])
            simi_li.append(tmp_simi)
        simi_arr = tr.stack(simi_li, -1).unsqueeze(0)
        return simi_arr
    


def img_enhance_main(args):
    with tr.no_grad():
        device = args.device_name
        if device is None:
            device = select_device()

        logging.info("Loding index and spots data ...")
        dataset = RedeVizImgBinIndex(args.index, args.cell_radius, device)
        spot_data, total_UMI_arr, x_range, y_range = load_spot_data(
            args.spot, args.x_index_label, args.y_index_label, args.gene_name_label, args.UMI_label, args.max_expr_ratio, dataset
        )

        if args.mid_signal_cutoff is None:
            logging.info("Computing global coverage threshold ...")
            args.mid_signal_cutoff = get_ave_smooth_cov(total_UMI_arr)
            logging.info(f"The global coverage threshold is {args.mid_signal_cutoff}")

        is_empty = False
        if args.slice_x is not None:
            assert args.slice_y
            _, x_min, y_min, _ = tr.min(spot_data.indices(), 1)[0].numpy()
            if (x_range <= args.slice_x[0]) | (y_range <= args.slice_y[0]) | (x_min <= args.slice_x[1]) | (y_min <= args.slice_y[1]):
                is_empty = True
            else:
                args.slice_x[1] = min(args.slice_x[1], x_range)
                args.slice_y[1] = min(args.slice_y[1], y_range)
                if min((args.slice_x[1] - args.slice_x[0]), (args.slice_y[1] - args.slice_y[0])) < (4 * dataset.max_bin_size):
                    raise ValueError("Slice region is too small")
                spot_data = SparseTenserSlice2D(spot_data, args.slice_x[0], args.slice_x[1], args.slice_y[0], args.slice_y[1])
                total_UMI_arr =  total_UMI_arr[:, args.slice_x[0]: args.slice_x[1], args.slice_y[0]: args.slice_y[1], :]
                x0 = args.slice_x[0]
                y0 = args.slice_y[0]
        else:
            x0 = 0
            y0 = 0

        if tr.sparse.sum(spot_data) == 0:
            is_empty = True
        
        if is_empty:
            with open(args.output, "w") as f:
                header = ["x", "y", "EmbeddingState", "Embedding1", "Embedding2", "Embedding3", "LabelTransfer", "ArgMaxCellType", "RefCellTypeScore", "OtherCellTypeScore", "BackgroundScore"]
                f.write("\t".join(header)+"\n")
            return None

        if args.ave_bin_dist_cutoff is None:
            args.ave_bin_dist_cutoff = max(2, int(10 / dataset.embedding_resolution))

        expand_size = int((dataset.max_bin_size - 1) / 2) + dataset.cell_radius
        with open(args.output, "w") as f:
            header = ["x", "y", "EmbeddingState", "Embedding1", "Embedding2", "Embedding3", "LabelTransfer", "ArgMaxCellType", "RefCellTypeScore", "OtherCellTypeScore", "BackgroundScore"]
            f.write("\t".join(header)+"\n")
            for tmp_spot_data, tmp_total_UMI_arr, x_start, y_start in div_spot(spot_data, total_UMI_arr, expand_size, step=args.window_size):
                tmp_spot_data = tmp_spot_data.to(device)
                tmp_total_UMI_arr = tmp_total_UMI_arr.to(device)
                x_start = x_start + x0
                y_start = y_start + y0
                x_end = min(x_start+args.window_size-1, x_range-1)
                y_end = min(y_start+args.window_size-1, y_range-1)
                logging.info(f"Spot region: x: {x_start}-{x_end}, y: {y_start}-{y_end}")
                model = RedeVizImgBinModel(dataset, tmp_spot_data, tmp_total_UMI_arr)
                model.compute_all(args.mid_signal_cutoff, args.neighbor_close_label_fct, args.signal_cov_score_fct, args.is_in_ref_score_fct, args.argmax_prob_score_fct, args.ave_bin_dist_cutoff, args.update_num)
                for data in model.iter_result(skip_bg=True):
                    if min(data[0], data[1]) < dataset.cell_radius:
                        continue
                    if min((model.cos_simi_range[0] - data[0]), (model.cos_simi_range[1] - data[1])) <= dataset.cell_radius:
                        continue
                    data[0] = data[0] + x_start - dataset.cell_radius
                    data[1] = data[1] + y_start - dataset.cell_radius
                    f.write("\t".join(list(map(str, data)))+"\n")
                model.detach()
                tmp_spot_data.detach()
                tmp_total_UMI_arr.detach()
                if tr.cuda.is_available():
                    tr.cuda.empty_cache()

